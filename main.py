# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AH41-pWZK2UT_tDPOAdok0QOli2ljTMd
"""

from google.colab import files

    uploaded = files.upload()

    for fn in uploaded.keys():
       print('User uploaded file "{name}" with length {length} bytes'.format(name=fn, length=len(uploaded[fn])))

import sys
import pandas 
import matplotlib.pyplot as plt
import seaborn as sns
import sklearn

from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score
from sklearn import linear_model,preprocessing
# %matplotlib inline

print("python version:", sys.version)
print("pandas version:", pandas._version_)
print("matplotlib version:", matplotlib._version_)
print ("seaborn version:",seaborn._version_)
print ("sklearn:", sklearn._version_)



import warnings
warnings.filterwarnings('ignore')

#load data
games= pandas.read_csv('games.csv')



#print the names of the columns in the game
print(games.columns)
print(games.shape)

#make a histogram of all the ratings in the average rating column
plt.hist(games['average_rating'])
plt.xlabel('Average Rating')
plt.ylabel('Number of games')
plt.show()

#print the first row of all the games with zero scores
print(games[games["average_rating"]==0].iloc[0])


#print the first row of games with scores greater than 0
print(games[games["average_rating"]> 0].iloc[0])

#remove any rows without user reviews
games=games[games["users_rated"]> 0]

#remove any rows with missing rows
games=games.dropna(axis=0)

#make a histogram of all the ratings in the average rating 
plt.hist(games['average_rating'])
plt.xlabel('Average Rating')
plt.ylabel('Number of games')
plt.show()

print(games.columns)

#correlation matrix
corrmat=games.corr()
fig=plt.figure(figsize=(12,9))

sns.heatmap(corrmat, vmax =8, square= True)
plt.show()

#get all the columns from the data grame

columns= games.columns.tolist()

#filter the columns to remove data we do not want
columns=[c for c in columns if c not in["bayes_average_rating", "average_rating", "type","name", "id"]]

#store the variable we'll be predicting on
target = "average_rating"

#generating train and test datasets
from sklearn.model_selection import train_test_split

#generate training set

train = games.sample(frac=0.8, random_state= 1)

#select anything not in the training set and put in the test
test= games.loc[~games.index.isin(train.index)]
#print shapes
print(train.shape)
print(test.shape)

# import linear regression model
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

#initialize the model class
LR = LinearRegression()

#fit the model to the training data
LR.fit(train[columns], train[target])

#Generate prediction for the test set
predictions = LR.predict(test[columns])

#compute error between test prediction and actual value
mean_squared_error(predictions, test[target])

#import the random forest model
from sklearn.ensemble import RandomForestRegressor
#initialize the model
RFR = RandomForestRegressor(n_estimators=100, min_samples_leaf=10, random_state=1)

#fit to data
RFR.fit(train[columns], train[target])

#make predictions 
predictions= RFR.predict(test[columns])

#compute the error between test prediction and actual value
mean_squared_error(predictions, test[target])

test[columns].iloc[0]

#make this prediction with both models
rating_LR = LR.predict(test[columns].iloc[0].values.reshape(1,-1))
rating_RFR = RFR.predict(test[columns].iloc[0].values.reshape(1,-1))

#print the predictions
print(rating_LR)
print(rating_RFR)

#print actual value
test[target].iloc[0]